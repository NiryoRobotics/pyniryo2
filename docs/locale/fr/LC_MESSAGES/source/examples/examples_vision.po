# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, Niryo All rights reserved. No part of this document
# may be reproduced or transmitted in any form or by any means without prior
# written consent of Niryo SAS
# This file is distributed under the same license as the PyNiryo2 package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PyNiryo2 v1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-01-26 15:44+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../source/examples/examples_vision.rst:2
msgid "Examples: Vision"
msgstr ""

#: ../../source/examples/examples_vision.rst:4
msgid "This page shows how to use Ned's vision set"
msgstr ""

#: ../../source/examples/examples_vision.rst:7
msgid ""
"If you want see more about Ned's vision functions, you can look at "
":ref:`PyNiryo - Vision<source/api_doc/vision:Vision>`"
msgstr ""

#: ../../source/examples/examples_vision.rst:9
msgid ""
"If you want to see how to do image processing, go check out the Pyniryo "
"(first version) doc."
msgstr ""

#: ../../source/examples/examples_vision.rst:12
msgid ""
"Even if you do not own a Vision Set, you can still realize these examples"
" with the Gazebo simulation version"
msgstr ""

#: ../../source/examples/examples_vision.rst:16
msgid ""
"If you are using the real robot, make sure the environment around it is "
"clear"
msgstr ""

#: ../../source/examples/examples_vision.rst:20
msgid "Needed piece of code"
msgstr ""

#: ../../source/examples/examples_vision.rst:22
msgid ""
"In order to achieve following examples, you need to have create a vision "
"workspace. In this page, the workspace used is named ``workspace_1``. To "
"create it, the user should go on Niryo Studio !"
msgstr ""

#: ../../source/examples/examples_vision.rst:26
msgid ""
"As the examples start always the same, add the following lines at the "
"beginning of codes ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:62
msgid ""
"All the following examples are only of part of what can be made with the "
"API in terms of vision. We advise you to look at :ref:`API - "
"Vision<source/api_doc/vision:Vision>` to understand more deeply"
msgstr ""

#: ../../source/examples/examples_vision.rst:67
msgid "Simple Vision Pick & Place"
msgstr ""

#: ../../source/examples/examples_vision.rst:68
msgid ""
"The goal of a Vision Pick & Place is the same as a classical Pick & "
"Place, with a close difference : the camera detects where the robot has "
"to go in order to pick !"
msgstr ""

#: ../../source/examples/examples_vision.rst:71
msgid ""
"This short example show how to do your first vision pick using the "
":meth:`~.vision.Vision.vision_pick` function : ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:85
msgid "Code Details - Simple Vision Pick and Place"
msgstr ""

#: ../../source/examples/examples_vision.rst:87
msgid ""
"To execute a Vision pick, we firstly need to go to a place where the "
"robot will be able to see the workspace ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:92
msgid ""
"Then, we try to perform a vision pick in the workspace with the "
":meth:`~.vision.Vision.vision_pick` function ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:98
msgid ""
"Variables ``shape_ret`` and ``color_ret`` are respectively of type "
":class:`~.vision.enums.ObjectShape` and "
":class:`~.vision.enums.ObjectColor`, and store the shape and the color of"
" the detected object ! We won't use them for this first example."
msgstr ""

#: ../../source/examples/examples_vision.rst:103
msgid ""
"The ``obj_found`` variable is a boolean which indicates whereas an object"
" has been found and picked, or not. Thus, if the pick worked, we can go "
"place the object at the place pose. ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:110
msgid "Finally, we turn learning mode on::"
msgstr ""

#: ../../source/examples/examples_vision.rst:116
msgid "If you ``obj_found`` variable indicates ``False``, check that :"
msgstr ""

#: ../../source/examples/examples_vision.rst:118
msgid "Nothing obstruct the camera field of view"
msgstr ""

#: ../../source/examples/examples_vision.rst:119
msgid "Workspace's 4 markers are visible"
msgstr ""

#: ../../source/examples/examples_vision.rst:120
msgid "At least 1 object is placed fully inside the workspace"
msgstr ""

#: ../../source/examples/examples_vision.rst:123
msgid "First conditioning via Vision"
msgstr ""

#: ../../source/examples/examples_vision.rst:124
msgid ""
"In most of use cases, the robot will need to perform more than one Pick &"
" Place. In this example, we will see how to condition multiple objects "
"according to a straight line ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:155
msgid "Code Details - First Conditioning via Vision"
msgstr ""

#: ../../source/examples/examples_vision.rst:157
msgid ""
"We want to catch ``max_catch_count`` objects, and space each of them by "
"``offset_size`` meter ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:163
msgid "We start a loop until the robot has caught ``max_catch_count`` objects ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:168
#: ../../source/examples/examples_vision.rst:274
msgid ""
"For each iteration, we firstly go to the observation pose and then, try "
"to make a vision pick in the workspace ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:176
msgid ""
"If the vision pick failed, we wait 0.1 second and then, start a new "
"iteration ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:182
#: ../../source/examples/examples_vision.rst:289
msgid ""
"Else, we compute the new place position according to the number of "
"catches, and then, go placing the object at that place ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:188
msgid "We also increment the ``catch_count`` variable ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:192
#: ../../source/examples/examples_vision.rst:313
msgid "Once the target catch number is achieved, we go to sleep ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:198
msgid "Multi Reference Conditioning"
msgstr ""

#: ../../source/examples/examples_vision.rst:199
msgid ""
"During a conditioning task, objects may not always be placed as the same "
"place according to their type. In this example, we will see how to align "
"object according to their color, using the color element "
":class:`~.vision.enums.ObjectColor` returned by "
":meth:`~.vision.Vision.vision_pick` function ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:253
msgid "Code Details - Multi Reference Conditioning"
msgstr ""

#: ../../source/examples/examples_vision.rst:255
msgid ""
"We want to catch objects until Vision Pick failed ``max_failure_count`` "
"times. Each of the object will be put on a specific column according to "
"its color. The number of catches for each color will be store on a "
"dictionary ``count_dict`` ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:281
msgid ""
"If the vision pick failed, we wait 0.1 second and then, start a new "
"iteration, without forgetting the increment the failure counter ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:308
msgid ""
"We increment the ``count_dict`` dictionary and reset "
"``try_without_success`` ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:318
msgid "Sorting Pick with Conveyor"
msgstr ""

#: ../../source/examples/examples_vision.rst:320
msgid ""
"An interesting way to bring objects to the robot, is the use of a "
"Conveyor Belt. In this examples, we will see how to catch only a certain "
"type of object by stopping the conveyor as soon as the object is detected"
" on the workspace ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:367
msgid "Code Details - Sort Picking"
msgstr ""

#: ../../source/examples/examples_vision.rst:369
msgid ""
"Firstly, we initialize your process : we want the robot to catch 4 Red "
"Circles. To do so, we set variables ``shape_expected`` and "
"``color_expected`` with :attr:`ObjectShape.CIRCLE "
"<pyniryo2.vision.enums.ObjectShape.CIRCLE>` and :attr:`ObjectColor.RED "
"<pyniryo2.vision.enums.ObjectColor.RED>` ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:379
msgid ""
"We activate the connection with the conveyor and start a loop until the "
"robot has caught ``max_catch_count`` objects ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:387
msgid ""
"For each iteration, we firstly run the conveyor belt (if the later is "
"already running, nothing will happen), then go to the observation pose ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:395
msgid ""
"We then check if an object corresponding to our criteria is in the "
"workspace. If not, we wait 0.5 second and then, start a new iteration ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:405
msgid "Else, stop the conveyor and try to make a vision pick ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:416
msgid "If Vision Pick succeed, compute new place pose, and place the object ::"
msgstr ""

#: ../../source/examples/examples_vision.rst:424
msgid ""
"Once the target catch number is achieved, we stop the conveyor and go to "
"sleep ::"
msgstr ""

